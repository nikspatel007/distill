workflow: session-insights-bootstrap-v2
description: Development workflow for session-insights CLI tool (v2 - with decomposition, KPI alignment, and circuit breakers)
agents:
- role: engineer
- role: reviewer
states:
  start:
    type: initial
    auto_transition: engineering
  engineering:
    instructions: |
      Implement the assigned task for the session-insights CLI tool.

      PHASE AWARENESS - YOU ARE IN VALIDATION MODE:
      The construction phase is complete. Measurers and pipelines exist but have
      NOT been fully validated against real data. Your priorities reflect this phase.

      MANDATORY FIRST STEP - MEASURE BEFORE BUILDING:
      Before writing ANY new code, run the existing KPI measurers against real data:
        uv run pytest tests/ -x -q
        uv run python -m session_insights analyze --dir . --global
      Capture and record the ACTUAL measured values for each KPI.
      If a measurer fails on real data, fixing it IS your task.
      Do NOT proceed to new features until measurers produce real numbers.

      KPI PRIORITY ORDER:
      1. tests_pass - Run the full test suite. Fix failures. This validates everything else.
      2. project_detection - Run detection against known projects, measure accuracy.
      3. Remaining KPIs - Only after 1 and 2 are green.

      TASK DECOMPOSITION REQUIREMENT:
      Do NOT work on monolithic "fix everything" tasks. Each task must target
      exactly ONE KPI with a clear acceptance criterion, e.g.:
        - "Make tests_pass reach 100% by fixing test_cli_skeleton"
        - "Improve project_detection accuracy to 70% on sample data"
      If your assigned task is too broad, decompose it before starting.

      MANDATORY LAST STEP - MEASURE AFTER BUILDING:
      After completing work, re-run all measurers and include a MEASURED DATA
      section in your done signal with before/after values for each KPI.
      Format: KPI_NAME: before_value -> after_value (measured, not estimated)

      Signal "done" only when:
      - All tests pass (uv run pytest tests/ -x -q)
      - You have measured KPI values (not estimates) to report
    on_signal:
      done:
        from: engineer
        next: reviewing
    timeout:
      duration: 30m
      action: nudge
  reviewing:
    instructions: |
      Review the implementation for correctness and KPI impact.

      MANDATORY VERIFICATION:
      1. Run the full test suite: uv run pytest tests/ -x -q --cov=session_insights
      2. Verify the engineer included MEASURED KPI data (not estimates) in their
         done signal. If they did not, signal needs_revision immediately.
      3. Verify the claimed KPI improvements by re-running the relevant measurers.
      4. Check that the task targeted a specific KPI, not a vague remediation.

      REJECT if:
      - Tests fail
      - No measured KPI data provided
      - KPI values are estimates rather than measured outputs
      - Task was too broad ("fix multiple things") without clear KPI targeting

      Signal "approved" if measured KPI data confirms improvement.
      Signal "needs_revision" with specific feedback if changes needed.

      Include a git diff summary and measured KPI values in your signal message.
    on_signal:
      approved:
        from: reviewer
        next: finalize
      needs_revision:
        from: reviewer
        next: engineering
    timeout:
      duration: 15m
      action: nudge
  finalize:
    type: terminal
    on_entry:
    - action: commit
