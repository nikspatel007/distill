# DDD Restructuring Design

## Goal

Restructure Distill from a flat module layout into proper Domain-Driven Design with bounded contexts, a canonical content store, and clear dependency rules.

## Migration Strategy

Merge current `feat/reading-content-items` branch to `main` first. Then incremental PRs — one domain per PR. Smallest blast radius per change.

---

## Bounded Contexts (7 Domains)

| Domain | Responsibility | Produces | Consumes |
|--------|---------------|----------|----------|
| **journal** | Sessions → daily prose | Journal entries → content store | Sessions (parsers), working memory |
| **intake** | External sources → daily digest | Reading digests → content store | RSS/browser/gmail/etc, seeds |
| **blog** | Journal + intake → weekly/thematic posts | Blog posts → content store | Journal entries, intake digests, memory |
| **brainstorm** | Research → content ideas | Seed ideas → seed store | HN, arXiv, RSS, existing seeds |
| **graph** | Sessions → knowledge graph | Graph nodes/edges, context injection | Session JSONL files |
| **content** | Canonical content lifecycle | Published content → platforms | All domain output |
| **memory** | Cross-domain memory warehouse | Aggregated threads, entities, daily entries | All domain memory contributions |

**Key rule:** Domains never import from each other's internals. Shared concepts live in `shared/`. Domains communicate through the content store or through the pipeline orchestration layer.

---

## Content Store — The Spine

The content store owns every piece of content from creation through publishing. It replaces the scattered state files (`.blog-state.json`, `.daily-social-state.json`, `.distill-review-queue.json`).

### Models

```python
class ContentStatus(StrEnum):
    DRAFT = "draft"           # Generated by a domain pipeline
    REVIEW = "review"         # Queued for human review in Studio
    READY = "ready"           # Approved, awaiting publish
    PUBLISHED = "published"   # Sent to at least one platform
    ARCHIVED = "archived"     # Retired

class ContentType(StrEnum):
    WEEKLY = "weekly"
    THEMATIC = "thematic"
    DIGEST = "digest"         # Intake daily digest
    DAILY_SOCIAL = "daily_social"
    SEED = "seed"

class ImageRecord(BaseModel):
    filename: str             # "weekly-2026-W08-hero.png"
    role: str                 # "hero", "inline", "social"
    prompt: str = ""          # Generation prompt used
    relative_path: str = ""   # "images/weekly-2026-W08-hero.png"

class PlatformContent(BaseModel):
    platform: str             # "ghost", "x", "linkedin", "slack"
    content: str              # Adapted text
    published: bool = False
    published_at: datetime | None = None
    external_id: str = ""     # Postiz post ID, Ghost post ID

class ChatMessage(BaseModel):
    role: str                 # "user" or "assistant"
    content: str
    timestamp: str

class ContentRecord(BaseModel):
    slug: str                 # Unique identifier
    content_type: ContentType
    title: str
    body: str                 # Canonical markdown
    status: ContentStatus = ContentStatus.DRAFT
    created_at: datetime
    source_dates: list[date] = []
    tags: list[str] = []
    images: list[ImageRecord] = []
    platforms: dict[str, PlatformContent] = {}
    chat_history: list[ChatMessage] = []
    metadata: dict[str, Any] = {}
    file_path: str = ""       # Where the .md lives on disk
```

### Store Interface

```python
class ContentStore:
    def __init__(self, output_dir: Path): ...

    # Write
    def upsert(self, record: ContentRecord) -> None
    def update_status(self, slug: str, status: ContentStatus) -> None
    def save_platform_content(self, slug: str, platform: str, content: PlatformContent) -> None

    # Read
    def get(self, slug: str) -> ContentRecord | None
    def list(self, content_type: ContentType | None = None, status: ContentStatus | None = None) -> list[ContentRecord]
    def exists(self, slug: str) -> bool

    # Images
    def add_image(self, slug: str, image: ImageRecord) -> None
    def get_images(self, slug: str) -> list[ImageRecord]

    # Lifecycle
    def mark_published(self, slug: str, platform: str, external_id: str) -> None
```

### Backing

Single JSON file (`.distill-content-store.json`). The `.md` files on disk are still written for Obsidian compatibility — the store is the index, files are the content.

### What It Replaces

- `.blog-state.json` → `content_store.exists(slug)`
- `.distill-review-queue.json` → `record.status` + `record.platforms` + `record.chat_history`
- `.daily-social-state.json` → records with `content_type=DAILY_SOCIAL`

### What It Doesn't Replace

- `UnifiedMemory` → stays in `memory/` domain (cross-session context, not content)
- `SeedStore` → stays in `intake/` (seeds are ideas, not content until they produce a post)
- `BlogMemory` → stays in `blog/` (dedup/cross-referencing is blog-specific logic)

### Image Generation Per Content Type

| Content Type | Hero | Inline | Hero Aspect | Social Crop |
|---|---|---|---|---|
| `weekly` | 1 | 1-2 | 16:9 | 1:1 center-crop |
| `thematic` | 1 | 1-2 | 16:9 | 1:1 center-crop |
| `digest` | 1 | 0 | 16:9 | — |
| `daily_social` | 1 | 0 | 3:2 | Already social-sized |

The existing image generation pipeline (mood-indexed style prefixes, visual metaphor extraction prompt, Gemini generation) is strong and stays as-is. `ImageRecord.prompt` stores the generation prompt so Studio can offer "regenerate with different mood."

---

## Domain Internal Structure

Each domain has two files + `__init__.py`:

```
src/blog/
    __init__.py     # Public API re-exports
    models.py       # Pure data: Pydantic models, enums, dataclasses
    services.py     # Business logic: synthesizers, detectors, gatherers
```

### Layer Rules

- **models.py** — No side effects, no I/O. Imports from `shared/` only.
- **services.py** — Stateless business logic. Can call `shared/llm.py`, can read `shared/` utilities. Returns data, never writes to disk.
- **`__init__.py`** — Re-exports the public API. This is what pipeline/ and cli.py import.

### No app.py

Domains export functions and classes. Pipeline is the plumbing. Two layers, not three.

| Layer | Owns | Imports from |
|---|---|---|
| **domain** (`blog/`, `journal/`, etc.) | models + services | `shared/` only |
| **pipeline** (`pipeline/`) | orchestration + plumbing | domain public APIs, `content/`, `shared/` |
| **cli** (`cli.py`) | user interface | `pipeline/`, domain public APIs for simple reads |

### Domain Public APIs

```python
# src/blog/__init__.py
from blog.models import BlogPostType, ThemeDefinition, WeeklyContext, ThematicContext
from blog.services import BlogSynthesizer, detect_themes, gather_evidence

# src/journal/__init__.py
from journal.models import JournalEntry, DailyContext
from journal.services import JournalSynthesizer, build_daily_context

# src/intake/__init__.py
from intake.models import ContentItem, ContentSource
from intake.services import create_parser, get_configured_parsers, run_intelligence

# src/brainstorm/__init__.py
from brainstorm.models import ResearchItem, ContentIdea, SourceTier
from brainstorm.services import analyze_research, fetch_all_sources

# src/graph/__init__.py
from graph.models import GraphNode, GraphEdge
from graph.services import build_graph, query_graph, generate_context

# src/content/__init__.py
from content.models import ContentRecord, ContentStatus, ContentType, ImageRecord, PlatformContent
from content.store import ContentStore

# src/memory/__init__.py
from memory.models import UnifiedMemory, MemoryThread, EntityRecord, DailyEntry
from memory.services import load_memory, save_memory, migrate_memory
```

### Pipeline as Plumbing

```python
# src/pipeline/blog.py — example
from distill.blog import BlogSynthesizer, detect_themes, gather_evidence
from distill.content import ContentStore, ContentRecord, ContentType
from distill.shared.config import load_config

def generate_blog_posts(output_dir: Path) -> list[ContentRecord]:
    config = load_config()
    store = ContentStore(output_dir)
    synth = BlogSynthesizer(config.blog)

    # Weekly
    for week_context in build_weekly_contexts(...):
        prose = synth.synthesize_weekly(week_context)
        store.upsert(ContentRecord(slug=..., body=prose, ...))

    # Thematic
    for theme, evidence in detect_themes(entries, store):
        prose = synth.synthesize_thematic(theme, evidence)
        store.upsert(ContentRecord(slug=..., body=prose, ...))
```

### Import Rule

```
models.py    → shared/ only
services.py  → own models.py, shared/
__init__.py  → own models.py, own services.py
pipeline/    → domain __init__ exports, content/, shared/
cli.py       → pipeline/, domain __init__ exports
```

**Nothing imports from another domain's services.py or models.py directly.**

---

## shared/ — Stateless Utilities Only

```
src/shared/
    __init__.py
    config.py          # DistillConfig, load_config(), ProjectConfig
    editorial.py       # EditorialStore, EditorialNote
    embeddings.py      # EmbeddingGenerator (optional dep)
    errors.py          # PipelineError, ConfigError, etc.
    images.py          # ImageGenerator (Gemini wrapper)
    llm.py             # call_claude(), strip_json_fences()
    narrative.py       # enrich_session_summary()
    notifications.py   # send_notification()
    store.py           # JsonStore, PgvectorStore (generic key-value)
```

**Rule:** shared/ contains only stateless utilities and cross-domain infrastructure. If it has business logic specific to one domain, it belongs in that domain.

**Does NOT go in shared/:**
- `BlogSynthesizer` → blog domain logic
- `SeedStore` → intake domain state
- `BlogMemory` → blog domain memory
- `WorkingMemory` → journal domain memory
- `UnifiedMemory` → memory domain (its own bounded context)

---

## Memory Domain — The Data Warehouse

```
src/memory/
    __init__.py        # exports UnifiedMemory, MemoryThread, EntityRecord, etc.
    models.py          # UnifiedMemory, DailyEntry, MemoryThread, EntityRecord, PublishedRecord
    services.py        # load, save, migrate, merge, query
```

UnifiedMemory aggregates across domains — blog reads threads to detect series, journal writes daily entries, intake contributes entity records. It's genuinely cross-domain, so it's its own bounded context rather than a utility.

Domain-specific memory stays in its domain:
- `blog/models.py` — `BlogMemory`, `BlogPostSummary` (cross-referencing for dedup)
- `journal/models.py` — `WorkingMemory` (session context carry-forward)
- `intake/models.py` — `IntakeMemory` (seen URLs, dedup state)

---

## What Stays Unchanged

| Module | Location | Why |
|---|---|---|
| `integrations/` | `src/integrations/` | Already a clean leaf — zero internal imports |
| `parsers/` | `src/parsers/` | Session parsing, own concern, not a DDD domain |
| `formatters/` | `src/formatters/` | Legacy Obsidian formatting, used by core.py |
| `measurers/` | `src/measurers/` | KPI measurement, separate concern |
| `pipeline/` | `src/pipeline/` | Cross-domain orchestration (plumbing layer) |
| `cli.py` | `src/cli.py` | Thin CLI, calls pipeline functions |
| `core.py` | `src/core.py` | Original orchestration, gradually replaced by pipeline/ |

---

## Final Package Layout

```
src/
    blog/                    # Blog domain
        __init__.py
        models.py
        services.py
        publishers/          # Blog output formatters (Obsidian, Ghost, Markdown, Postiz)
    journal/                 # Journal domain
        __init__.py
        models.py
        services.py
    intake/                  # Intake domain
        __init__.py
        models.py
        services.py
        parsers/             # Source parsers (RSS, browser, gmail, etc.)
        publishers/          # Intake output formatters
    brainstorm/              # Brainstorm domain
        __init__.py
        models.py
        services.py
    graph/                   # Knowledge graph domain
        __init__.py
        models.py
        services.py
    content/                 # Content lifecycle domain (the spine)
        __init__.py
        models.py
        store.py
    memory/                  # Cross-domain memory warehouse
        __init__.py
        models.py
        services.py
    shared/                  # Stateless utilities
        __init__.py
        config.py
        editorial.py
        embeddings.py
        errors.py
        images.py
        llm.py
        narrative.py
        notifications.py
        store.py
    integrations/            # External service clients (unchanged)
    parsers/                 # Session parsers (unchanged)
    formatters/              # Legacy formatters (unchanged)
    measurers/               # KPI measurers (unchanged)
    pipeline/                # Cross-domain orchestration (plumbing)
    cli.py                   # CLI entry point
    core.py                  # Legacy orchestration (gradually replaced)
```

---

## Migration Order (Incremental PRs)

1. **PR 1: content/** — New domain. ContentRecord, ContentStore. No consumers yet.
2. **PR 2: shared/** — Move llm.py, config.py, errors.py, etc. Update all imports.
3. **PR 3: memory/** — Extract from current memory.py. Update consumers.
4. **PR 4: journal/** — Restructure into models.py + services.py. Update pipeline/.
5. **PR 5: blog/** — Restructure into models.py + services.py. Wire to content store.
6. **PR 6: intake/** — Restructure into models.py + services.py. Wire to content store.
7. **PR 7: brainstorm/** — Restructure into models.py + services.py.
8. **PR 8: graph/** — Restructure into models.py + services.py.
9. **PR 9: pipeline/** — Rewrite as pure plumbing calling domain public APIs + content store.
10. **PR 10: cli.py** — Thin CLI calling pipeline functions.
